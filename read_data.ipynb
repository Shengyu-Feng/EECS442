{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import string\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.autograd import Variable\n",
    "import random\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from preprocess import *\n",
    "from darknet import *\n",
    "from util import *\n",
    "import pickle as pkl\n",
    "batch_size = 20\n",
    "classes = ['Car', 'Van', 'Truck', 'Pedestrian', 'Person_sitting','Cyclist','Tram','Misc','DontCare']\n",
    "class_to_id = dict(zip(classes,range(9)))\n",
    "id_to_class = dict(zip(range(9),classes))\n",
    "label_dir = \"training/label_2\"\n",
    "train_dir = 'training/image_2'\n",
    "test_dir = 'testing/image_2'\n",
    "colors = pkl.load(open(\"pallete\", \"rb\"))\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "def get_data(read_data = [1,1,0], size = [7481,7481,7518]):\n",
    "    label = []\n",
    "    train = []\n",
    "    test = []\n",
    "    index = 0\n",
    "    \n",
    "    if read_data[0]:\n",
    "        print('load label...')\n",
    "        for root, dirs, files in os.walk(label_dir):\n",
    "            for file in sorted(files):\n",
    "                lines = open(os.path.join(label_dir, file), encoding='utf-8').read().strip().split('\\n')\n",
    "                lines = [line.split() for line in lines]\n",
    "                lines = [[class_to_id[line[i]] if i==0 else float(line[i]) for i in range(15)] for line in lines]\n",
    "                lines = np.array(lines)\n",
    "                label.append(lines[:,np.array([0,4,5,6,7])])\n",
    "                #label.append(lines)\n",
    "                index += 1\n",
    "                if index >= size[0]:\n",
    "                    break\n",
    "    index = 0\n",
    "    if read_data[1]:\n",
    "        print('load train...')\n",
    "        for root, dirs, files, in os.walk(train_dir):\n",
    "            for file in sorted(files):\n",
    "                img = cv2.imread(os.path.join(train_dir,file))\n",
    "                train.append(img)\n",
    "                index += 1\n",
    "                if index >= size[1]:\n",
    "                    break\n",
    "    index = 0\n",
    "    if read_data[2]:\n",
    "        print('load test')\n",
    "        for root, dirs, files, in os.walk(test_dir):\n",
    "            for file in files:\n",
    "                img = cv2.imread(os.path.join(test_dir,file))\n",
    "                test.append(img)\n",
    "                index += 1\n",
    "                if index>=size[2]:\n",
    "                    break\n",
    "    return label, train, test\n",
    "\n",
    "def write(img, bboxes):\n",
    "    img_ = img.copy()\n",
    "    for bbox in bboxes:\n",
    "        label = \"{0}\".format(id_to_class[bbox[0].astype(int)])\n",
    "        c1 = tuple((bbox[1:3]).astype(np.int32))\n",
    "        c2 = tuple((bbox[3:5]).astype(np.int32))\n",
    "        color = random.choice(colors)\n",
    "        cv2.rectangle(img_, c1, c2, color, 1)\n",
    "        t_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_PLAIN, 1 , 1)[0]\n",
    "        c2 = c1[0] + t_size[0] + 3, c1[1] + t_size[1] + 4\n",
    "        cv2.rectangle(img_, c1, c2,color, -1)\n",
    "        cv2.putText(img_, label, (c1[0], c1[1] + t_size[1] + 4), cv2.FONT_HERSHEY_PLAIN, 1, [225,255,255], 1)\n",
    "    return img_\n",
    "\n",
    "class bboxData(Dataset):\n",
    "    def __init__(self, size=1000):\n",
    "        self.size = size\n",
    "        label, train, test = get_data(size=[size,size,0])\n",
    "        image = list(map(cv2.resize, train, [(416,416) for i in range(size)]))\n",
    "        self.image = torch.FloatTensor(image).permute(0,3,1,2).div(255.0)\n",
    "        for i in range(size):\n",
    "            h, w, c = train[i].shape\n",
    "            label_ = np.zeros_like(label[i])\n",
    "            label_[:,1] = label[i][:,1]*416/w\n",
    "            label_[:,3] = label[i][:,3]*416/w\n",
    "            label_[:,2] = label[i][:,2]*416/h\n",
    "            label_[:,4] = label[i][:,4]*416/h\n",
    "            label[i][:,1] = (label_[:,3] + label_[:,1])/832\n",
    "            label[i][:,2] = (label_[:,4] + label_[:,2])/832\n",
    "            label[i][:,3] = (label_[:,3] - label_[:,1])/416\n",
    "            label[i][:,4] = (label_[:,4] - label_[:,2])/416\n",
    "            label[i] = torch.Tensor(label[i])\n",
    "        self.label = pad_sequence(label,True)     \n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        sample = (self.image[idx],self.label[idx])\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load label...\n",
      "load train...\n"
     ]
    }
   ],
   "source": [
    "train_data = bboxData(size = 7481)\n",
    "model = Darknet('cfg/yolov3.cfg')\n",
    "model.load_weights(\"yolov3.weights\")\n",
    "model.module_list[81] = nn.Conv2d(1024,42,1,1)\n",
    "model.blocks[83]['classes'] = '9'\n",
    "model.module_list[93] = nn.Conv2d(512, 42,1,1)\n",
    "model.blocks[95]['classes'] = '9'\n",
    "model.module_list[105] = nn.Conv2d(256, 42,1,1)\n",
    "model.blocks[107]['classes'] = '9'\n",
    "\"\"\"\n",
    "model = Darknet('cfg/3dyolo.cfg')\n",
    "weights = torch.load('model_3dyolo.pth', map_location='cpu')\n",
    "model.load_state_dict(weights)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, trainloader, optimizer, device):\n",
    "    running_loss = 0\n",
    "    model.train()\n",
    "    for i, (images, labels) in enumerate(trainloader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        loss = model(images, labels,True)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        if (i +1) % 10 ==0:\n",
    "            print(\"Iteration %d: Training loss: %f\"%(i+1, running_loss/10))\n",
    "            running_loss = 0\n",
    "\n",
    "def validate(model, valloader, device):\n",
    "    running_loss = 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, (images, labels) in enumerate(valloader):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            loss = model(images, labels, True)\n",
    "            running_loss += loss.item()\n",
    "            total += 1\n",
    "        print(\"Validation loss: %f\"%(running_loss/total))\n",
    "\n",
    "train_size = int(0.9*len(train_data))\n",
    "val_size = len(train_data) - train_size\n",
    "trainset, valset = random_split(train_data, [train_size,val_size])\n",
    "trainloader = DataLoader(trainset, batch_size= batch_size, shuffle=False)\n",
    "valloader = DataLoader(valset, batch_size=1,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=1e-5)\n",
    "epoches = 2\n",
    "for epoch in range(epoches):\n",
    "    train(model, trainloader, optimizer, device)\n",
    "    validate(model,valloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), './model_3dyolo.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
